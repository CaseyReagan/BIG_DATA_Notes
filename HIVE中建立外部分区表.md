# Hive中建立外部分区表
本文借鉴内容：

## 总结
建立外部表的时候比较稳妥的做法是先建立分区，再Put数据文件到hdfs地址，这样最稳妥。如果要先Put数据，那可以以分区文件夹形式put，然后再挂载分区。

### （一）背景
在完成pdd用户拦截任务的时候，借鉴之前任务，做外部表输入导入的时候，遇到问题，分区无法挂载。
***

### （二）原理
hive中的表分为内部表和外部表：   
内部表（管理表）   
HDFS中为所属数据库目录下的子文件夹   
数据完全由Hive管理，删除表(元数据)会删除数据   
   
外部表（External Tables）   
数据保存在指定位置的HDFS路径中   
Hive不完全管理数据，删除表(元数据)不会删除数据   

简单说就是外部表和内部表不同，外部表的元数据（表结构和信息）是存储在metastore里的，而数据是存储在hdfs指定路径下的，要把二者关联起来，就要挂载分区。而删除分区的时候，hdfs路径下的数据文件是不会删除的。
***


### （三）建表过程
建立分区外部表之后，如果想导入数据的话，需要先建立对应的分区，可以用语句：
```sql
alter table table_name add if not exists partition (tx_dt=20221124);
```
之后检查show partitions看分区是否已经存在，如果想严谨一点可以使用hadoop命令fs -ls进去对应的地址查看该文件夹里是否为空（很可能以前有导入过数据，只删除分区不会删除数据，重新建立分区之后，这个数据会挂载到HIVE表内），如果不为空，需要用rm命令删除该文件。然后用以下命令放入数据。
```hadoop
hdfs dfs -put -f /a/b/c/D.20221124.txt hdfs://aa/bb/cc/D/tx_dt=20221124
```
这样之后用select命令指定分区就可以查到数据。   

第二种方法，如果一定要先导入数据，那就将数据文件例如D.txt放到一个名为"tx_dt=20221124"的文件夹下，把整个文件夹放到表D路径下，然后再执行建立分区进行挂载，似乎也是也可以的，未实践过。
***

### （四）MSCK REPAIR TABLE命令
见笔记"Hive中修复分区MSCK REPAIR TABLE"
